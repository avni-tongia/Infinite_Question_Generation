import json
from sentence_transformers import SentenceTransformer, util

# -------------------------------
# 1Ô∏è‚É£ Load the small embedding model (fast & reliable)
# -------------------------------
print("üöÄ Loading embedding model...")
model_name = "sentence-transformers/all-MiniLM-L6-v2"
model = SentenceTransformer(model_name)

# -------------------------------
# 2Ô∏è‚É£ Load the physics context file
# -------------------------------
print("üìö Loading physics context...")
with open("physics.context.txt", "r", encoding="utf-8") as f:

    context = f.read().split("\n")

# Remove empty lines if any
context = [line.strip() for line in context if line.strip()]

# -------------------------------
# 3Ô∏è‚É£ Encode the context for retrieval
# -------------------------------
print("üß† Encoding context paragraphs...")
context_embeddings = model.encode(context, convert_to_tensor=True)

# -------------------------------
# 4Ô∏è‚É£ Load sample questions
# -------------------------------
print("‚ùì Loading sample questions...")
with open("sample_queries.json", "r", encoding="utf-8") as f:
    questions = json.load(f)

# -------------------------------
# 5Ô∏è‚É£ Perform retrieval for each question
# -------------------------------
print("üîç Performing retrieval...")
results = []

for q in questions:
    query = q["question"]
    query_embedding = model.encode(query, convert_to_tensor=True)
    hits = util.semantic_search(query_embedding, context_embeddings, top_k=3)[0]
    top_contexts = [context[hit["corpus_id"]] for hit in hits]
    results.append({
        "question": query,
        "retrieved_contexts": top_contexts
    })

# -------------------------------
# 6Ô∏è‚É£ Save RAG results to JSON
# -------------------------------
print("üíæ Saving results to rag_results.json ...")
with open("rag_results.json", "w", encoding="utf-8") as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print("\n‚úÖ Retrieval complete! Check rag_results.json for outputs.")
