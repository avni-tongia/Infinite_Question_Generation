# ğŸ“˜ Multimodal HC Verma Pipeline

This repository processes the **HC Verma PDF** into a structured, multimodal dataset with **text, equations (LaTeX), figures, tables, and embeddings**.  
It produces a final `manifest.json` linking everything together for downstream **RAG, QA, and fine-tuning**.

---

## ğŸ”§ Features

- **Text extraction** with OCR fallback (Tesseract) for scanned pages.  
- **Chapter structuring** into JSON + Markdown.  
- **Examples/Problems scaffolding** for future parsing.  
- **Equation extraction** (text â†’ LaTeX, with image-equation stub).  
- **Figure extraction** (images + caption guesses).  
- **Table extraction** to CSV.  
- **Text embeddings** with SentenceTransformers.  
- **Image embeddings** (figures & equations) with CLIP.  
- **Cross-linking** into one coherent `manifest.json`.  
- **Single driver script (`run_pipeline.py`)** to run the entire pipeline end-to-end.  

---

## ğŸ–¥ï¸ Setup

### 1. Create virtual environment
Windows (PowerShell):
```bash
python -m venv venv
venv\Scripts\activate
```

macOS:
```bash
python3 -m venv venv
source venv/bin/activate
```

### 2. Install system dependencies
Windows (Chocolatey):
```bash
choco install tesseract ghostscript
```

macOS (Homebrew):
```bash
brew install tesseract ghostscript
```

### 3. Install Python dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

---

## ğŸ“‚ Folder Structure

```
your-repo/
â”‚
â”œâ”€â”€ Scripts/                  # all Python scripts
â”‚   â”œâ”€â”€ preprocess_pdf.py
â”‚   â”œâ”€â”€ structure_text.py
â”‚   â”œâ”€â”€ extract_examples_problems.py
â”‚   â”œâ”€â”€ build_embeddings.py
â”‚   â”œâ”€â”€ ocr_utils.py
â”‚   â”œâ”€â”€ extract_equations.py
â”‚   â”œâ”€â”€ extract_figures.py
â”‚   â”œâ”€â”€ extract_tables.py
â”‚   â”œâ”€â”€ build_multimodal_embeddings.py
â”‚   â””â”€â”€ index_manifest.py
â”‚
â”œâ”€â”€ data/                     # input + generated data
â”‚   â”œâ”€â”€ HC_Verma.pdf          # input book (only manual file)
â”‚   â”œâ”€â”€ hcverma_raw.txt
â”‚   â”œâ”€â”€ page_log.jsonl
â”‚   â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ hcverma_structured.json
â”‚   â”œâ”€â”€ hcverma_with_examples.json
â”‚   â”œâ”€â”€ equations/
â”‚   â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ tables/
â”‚   â”œâ”€â”€ vectors/
â”‚   â””â”€â”€ manifest.json
â”‚
â”œâ”€â”€ run_pipeline.py           # driver script (runs all steps in order)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸš€ How to Run

From the project root:
```bash
python run_pipeline.py
```

This will execute all steps in order automatically and generate outputs in the `data/` folder.  

---

## âœ… Outputs

- **Raw text:** `data/hcverma_raw.txt`  
- **Chapters:** `data/hcverma_structured.json`, `hcverma_structured.md`  
- **Examples/Problems scaffold:** `data/hcverma_with_examples.json`  
- **Equations (LaTeX + stubs):** `data/equations/equations.jsonl` (+ PNGs if image detection added)  
- **Figures:** `data/figures/figures.jsonl` + PNGs  
- **Tables:** `data/tables/tables.jsonl` + CSVs  
- **Embeddings:**  
  - Text â†’ `hcverma_embeddings.npy`, `hcverma_embeddings_with_metadata.json`  
  - Images â†’ `vectors/figures_clip.npy`, `vectors/equations_clip.npy` (+ JSON metadata)  
- **Manifest:** `data/manifest.json`